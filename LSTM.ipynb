{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e4b0374b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0', 'arr_1', 'arr_2', 'arr_3', 'arr_4', 'arr_5', 'arr_6', 'arr_7', 'arr_8', 'arr_9', 'arr_10', 'arr_11', 'arr_12', 'arr_13', 'arr_14', 'arr_15', 'arr_16', 'arr_17', 'arr_18', 'arr_19', 'arr_20', 'arr_21', 'arr_22', 'arr_23', 'arr_24', 'arr_25', 'arr_26', 'arr_27', 'arr_28', 'arr_29', 'arr_30', 'arr_31', 'arr_32', 'arr_33', 'arr_34', 'arr_35', 'arr_36', 'arr_37', 'arr_38', 'arr_39', 'arr_40', 'arr_41', 'arr_42', 'arr_43', 'arr_44', 'arr_45', 'arr_46', 'arr_47', 'arr_48', 'arr_49', 'arr_50', 'arr_51', 'arr_52', 'arr_53', 'arr_54', 'arr_55', 'arr_56', 'arr_57', 'arr_58', 'arr_59', 'arr_60', 'arr_61', 'arr_62', 'arr_63', 'arr_64', 'arr_65', 'arr_66', 'arr_67', 'arr_68', 'arr_69', 'arr_70', 'arr_71', 'arr_72', 'arr_73', 'arr_74', 'arr_75', 'arr_76', 'arr_77', 'arr_78', 'arr_79', 'arr_80', 'arr_81', 'arr_82', 'arr_83', 'arr_84', 'arr_85', 'arr_86', 'arr_87', 'arr_88', 'arr_89', 'arr_90', 'arr_91', 'arr_92', 'arr_93', 'arr_94', 'arr_95', 'arr_96', 'arr_97', 'arr_98', 'arr_99']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "630"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\"\"\"\n",
    "The .npz file format is a way to store a bunch of numpy arrays. I ran 100 simulations and \n",
    "stored the data in the file 'data.npz'.\n",
    "\"\"\"\n",
    "\n",
    "all_data = np.load('data.npz')\n",
    "file_names = all_data.files\n",
    "print(file_names)\n",
    "\n",
    "\"\"\"\n",
    "To retrieve the first simulation data, we would use the following:\n",
    "\"\"\"\n",
    "\n",
    "first_file_name = file_names[0]\n",
    "first_simulation_data = all_data[first_file_name]\n",
    "#print(first_simulation_data.shape)\n",
    "#print(first_simulation_data)\n",
    "##################################################################################################################\n",
    "\n",
    "# Importing all samples\n",
    "data = [first_simulation_data]\n",
    "\n",
    "for i in range (1, 99):\n",
    "    file_name = file_names[i]\n",
    "    simulation_data = all_data[file_name]\n",
    "    data.append(simulation_data)\n",
    "\n",
    "data = np.array(data, dtype=object)\n",
    "data[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "392e2bf1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99,)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "# inputs has size (batch_size, seq_len, input_size)\n",
    "\n",
    "# data = torch.Tensor(np.asarray(first_simulation_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9ec03efd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # lstm, linear are layers in the network\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        batch_size = data.shape[0]\n",
    "        \n",
    "        h_0 = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        c_0 = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        \n",
    "        out, (hidden, cell) = self.lstm(data, (h_0, c_0))\n",
    "        \n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out, (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "226204d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters and instantiate model\n",
    "\n",
    "input_size = 4\n",
    "output_size = 4\n",
    "hidden_dim = 32\n",
    "n_layers = 1\n",
    "\n",
    "lstm = LSTM(input_size=input_size, output_size=output_size, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "\n",
    "n_epochs = 100\n",
    "lr = 0.01\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(lstm.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "72764b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def training(n_epochs, model, optimizer, criterion, train_input, train_target):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        output, (hidden, cell) = model(train_input)\n",
    "        loss = criterion(output, train_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if epoch%10 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ba18898d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 20, 4])\n",
      "torch.Size([500, 20, 4])\n"
     ]
    }
   ],
   "source": [
    "# Wrangling data\n",
    "\"\"\"\"\n",
    "print(data[0].shape)\n",
    "train_prop = 0.9\n",
    "train_samples = round(data.shape[0] * train_prop)\n",
    "test_samples = data.shape[0] - train_samples\n",
    "\n",
    "train_input = data[test_samples:]\n",
    "print(train_input.shape)\n",
    "train_target = data\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# for now we will just use the first simulation\n",
    "train_set = data[0][90:]\n",
    "test_set = data[0][:90]\n",
    "\n",
    "# Use the first 20 4-number sequences to predict the next 20 4-number sequences\n",
    "def create_target(inputs):\n",
    "    x_train = [inputs[i:i+20] for i in range(len(inputs) - 40)]\n",
    "    y_train = [inputs[i+20:i+40] for i in range(len(inputs) - 40)]\n",
    "    \n",
    "    x_train = torch.stack(x_train)\n",
    "    y_train = torch.stack(y_train)\n",
    "    \n",
    "    return x_train, y_train\n",
    "\n",
    "train_set = torch.Tensor(train_set)\n",
    "train_input, train_target = create_target(train_set)\n",
    "\n",
    "print(train_input.shape)\n",
    "print(train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f0a9bb90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100............. Loss: 29083502592.0000\n",
      "Epoch: 20/100............. Loss: 12572798976.0000\n",
      "Epoch: 30/100............. Loss: 5525599232.0000\n",
      "Epoch: 40/100............. Loss: 2516692736.0000\n",
      "Epoch: 50/100............. Loss: 1231041664.0000\n",
      "Epoch: 60/100............. Loss: 680767616.0000\n",
      "Epoch: 70/100............. Loss: 444327520.0000\n",
      "Epoch: 80/100............. Loss: 341838464.0000\n",
      "Epoch: 90/100............. Loss: 296539872.0000\n",
      "Epoch: 100/100............. Loss: 275675968.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(4, 32, batch_first=True)\n",
       "  (linear): Linear(in_features=32, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training(n_epochs, lstm, optimizer, criterion, train_input, train_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
